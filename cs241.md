# Intro to OS

What is an operating system – no universal definition, but generally software acting as intermediary between user and hardware.

The main OS responsibility ius to allocate resources to use processes and control their execution. E.g. control access to memory when it is used by multiple processes.

![OS responsibilities](OS_responsibilities.png?raw=true "OS responsibilities")

Services of an operating system can be split to 2 categories: useful to user (run programs, io operations, file system management) and useful to the system (resource allocation, security)  

**Program execution stages:** load program into memory, execute program, stop program.

**I/O operations:** write something to file, take input from keyboard/mouse/peripherals. User processes don’t control devices directly - instead, the OS controls them and allows multiple processes to access the same IO devices.  

**File system management:** allows programs to read/write files and other complex actions, subject to permission management.  

**Communications between processes:** OS allows such communications between processes on the same computer or through a network. The main ways to do this are sharing memory or direct messages.

**Error handling:** caused by hardware failure, IO devices or bad software. The OS handles the error to prevent a full system crash and generally stops the process that created the error. Sometimes the OS cannot prevent a full system crash if the error occurs in a critical process.

**Resource allocation:** scheduling CPU time and other hardware resources to different processes to allow multiple processes to run concurrently. Considers type of process, speed of hardware, number of jobs to be executed etc.

**Accounting:** keeps track of which processes are running and the amount of resources used, useful for system admin for billing purposes or to find misbehaving processes.

**Security:** concurrent processes cannot interfere with each other or the OS itself (purposefully or otherwise), and must keep the system secure - process's shouldn't be able to access other process's memory space unless authorised.

**Kernel**: the core of an OS, loaded into memory at startup and always running – provides necessary services like memory management, process scheduling, file handling.  

**Kernel space**: part of memory which stores kernel, kept separate from user space where user processes are. The split is to prevent user processes from interfering with the kernel for both security and stability. User processes can access kernel space through system calls that require permissions, giving limited access if required and the user process is trusted.

**System calls:** an interface where the user processes can request services (privileged operations/instructions) from the kernel. System calls provide access the low-level functions done only by the OS, e.g. hardware resource management, file operations, IO device access, etc, and can be limited to only authorised processes to increase security.

**Dual mode operation:** the hardware operates in kernel mode or user mode depending on if the operations are requested by the OS or user processes. Privileged instructions are only executable in kernel mode as they could be abused by malicious user processes. System calls change the mode to 0/kernel, and the return from a call changes it to 1/user.

![OS kernel mode](OS_kernel_mode.png?raw=true "OS Kernel Mode")

# OS structure
OS structure is large and complex.

**Early OS:** simple structures with not well defined levels, e.g. several layers could access IO devices. Hardware didn’t support dual mode operation.

![Early OS/Unix structure](OS_early_unix.png?raw=true "Early OS/Unix structure")

**Early UNIX:** huge amount of functionality built into the single kernel layer. Very little overhead in system calls, but hard to maintain and modify due to interdependencies. These monolithic structures have elements that have carried over into modern OS.

**Layered approach:** each layer interacts with the layers above and below, capped by the hardware and user processes. Layer K uses the services of layer K-1 and provides services to layer K+1. Modular design allows for easy layer modification, as the services they require and need to provide are already specified, so can easily modify the implementation without changing functionality. However, layer definition can be difficult – it must be ensured that layer K+1 doesn’t require services from layers below K-1. Also, more kernel layers mean more system calls between layers, increasing the overhead of services provided to the user.  

**Microkernels:** modular design of kernel, remove all non-essential services from kernel and implement them as user services, e.g.

![OS microkernel services](OS_micro_kernels.png?raw=true "OS microkernel services")

**Advantages**:

- Easy to extend the kernel due to simplicity
- Security and reliability are better as there is less to go wrong in the kernel  

**Disadvantages:**

- Performance suffers as there is more user-kernel processes interaction, so more system call overhead

**Loadable kernel:** the most modern approach and used in Windows/Linux/MacOS. A micro-like kernel implements the core services while other complex kernel services are loaded and run as is required. Similar to layered as each module is specifically designed for one purpose, but any module can interact with any other, so easier to access other kernel services.

# Processes

**What is a process:** a program currently in execution (in memory). One application can create several processes.

**Process in memory:**

- Text – stores instructions
- Data – stores the global variables
- Heap – dynamically allocated memory
- Stack – stores local variables and function parameters e.g. return address of the function

**Process states:**

- New – process is being created
- Running – instructions from the process are being executed
- Waiting – the process is waiting for some event to occur
- Ready – the process is waiting to be assigned to a processor
- Terminated – process has finished execution

State change graph:

![Process state change](Process_state_change.png?raw=true "Process state change")

Process Control Block (PCB) 

OS maintains a PCB for each process – data structure tracking the process 

Keeps track of: 

Process state – running, waiting, ready, etc 

Program counter – location of next instruction in process 

CPU registers – contents of the CPU registers for use in case of interruptions 

CPU scheduling information – priorities, scheduling queue pointers 

Memory management info – locating process in the memory 

Accounting info – CPU time used, time since start 

IO status – list of files/IO devices in use by process 

Switching between processes 
 

Process Scheduling 

To maximise CPU use, processes are switched from on/off as others wait 

Process scheduler selects amoing available processes for next execution on CPU 

Job queue – set of all process in the new state (long term scheduler) 

Ready queue – set of all processes in the ready state (short term scheduler) 

Device queue – set of processes waiting for an IO device 

Queues – contains a head and a tail pointing to the next process to be serviced and the last one to be, processes can be inserted in any point in the queue depending on the priority 

 

Queuing diagram 
 

Schedulers 

Short term – selects the next process to be executed from the ready queue 

Invoked very frequently – at least once every 100ms 

Very fast – if takes 10ms to decide a process burst for 100ms, then 9% of CPU time is wasted 

Long term scheduler – selects processes in the new state to be brought into memory and ready queue 

Infrequent – can take minutes between creating one process and the next 

Controls number of processes in memory – when stable the arrival rate = compeletion rate 

Processes can be IO bound (more time doing IO than computation – short CPU burst) or CPU bound (more time doing computation – long CPU burst) - the long term scheduler tries to get a good mix of these processes 

Time-sharing systems like Linux/Windows don’t have a long term scheduler and dump all processes on the short term scheduler 

Process creation 

 A process may be created by another process 

Child processes can create more processes – forming a process tree 

Processes are identified using a process identifier PID 

 

‘ps’ is used in Linux to access running processes 

Resource (CPU, memory, file) sharing: 

The parent and child can share all resources 

The child can share a subset of the parents resources, e.g. CPU and not memory/file 

The parent and child share no resources 

Execution options: 

Parent and child execute concurrently 

Parents waits until children terminate 

Address space: 

Child’s address space is duplicate of parents (duplicated code, data and stack as parent) 

Child loads a new program into address space 

Fork() - can be used to create child processes from parents 

Child has PID=0 and the parent has PID=that of the child in the OS which is greater than 0 

Process Termination 

Terminates automatically after last statement is complete 

Also terminated using exit(), which returns status value to parent – parent can catch this to determine the success of the child process 

All resources are released after termination 

Between child process termination and parents receiving the exit code, the child is a zombie process 

The resources are released but the entry is still in the process table 

One the parent receives the exit status, the entry is removed 

What happens when parent exits before children exit? 

Children become orphan processes 

In UNIX systems, the init process is assigned as the parents 

Init thereafter periodically issues wait() to collect the exit status of all orphan processes to release the orphans PID and entry in process table 

Parent can terminate the execution of child process using abort() call 

Used when child takes up too much resources, no longer required or similar 

If parent is exiting and OS doesn’t allow orphan children then the child is terminated (and its children and so forth) - cascading termination 

Interprocess Communication 

Processes running concurrently may want to communicate with each other 

Sharing files 

Sharing data about the user activity in the process 

Etc 

Two methods: 

Shared memory 

Region of memory shared by communicating processes is created 

 

Shared memory typically inside one of the processes memory and other processes request access to it 

System calls used to create the shared memory, but no further use of kernel – less overhead 

More effort by programmer to maintain synchronization – ensure processes don’t try to access the same address at the same time 

 

 

Message passing 

Messages are directly exchanged between the communicating processes 

 

Kernel provides the commication channel, e.g. a buffer 

System calls to write/read the buffer 

Simplify job of programmer but increased overhead 

Must have at least send() and receive() to alow message passing – these are often system calls 

Implementation – direct/indirect, how send/receive is synchronised, buffer size 

Direct: 

Processes name each other explicitly in sending messages using PID or similar 

Links are establiushed automatically and is associated with only one pair of commuinicating processes 

Indirect: 

Messages sent through ‘mailbox’ using mailbox ID 

Processes can only communicate if they share a mailbox 

A link is established if processes share a common mailbox 

Links may be between many processes and pairs of processes may have several communication links 

 Synchronisation of system messages 

Blocking – creating synchronous messaging 

Blocking send – sender waits processing until the message is confirmed received 

Blocked receive – receiver waits processing until a message is available to receive 

Non blocking is asynchronous 

Buffering – A communication link is a buffer 

Zero capacity – the queue has length 0, so sender waits until receipient receives the message 

Bounded capacity – the queue has finite length and once the end is reached, the sender must wait until the recepient receives the message 

Unbounded capacity – sender never waits after sending message 

Producer-consumer paradigm 

Shared buffer/memory is filled by a producer and emptied by a consumer 

Consumer waits when the buffer is empty 

Producer waits when the buffer is full (if buffer space is unbounded, this never happens) 

Can create circular queue as the buffer space if limited – easier to produce code to write/read from it and not get overwritten 

Ordinary pipes 

Provide simple mechanism for one-way communication through message passing 

Producer sends input to pip, which outputs to the input of the consumer 

Used in terminal in Linux using ‘|’ 

Pipe() creates a pipe by creating 2 temporary files and linking them 

 

X is set to 10 above 

Named pipes 

Exist outside of process run-time, in a directory as a file 

No parent-child relationship needed between user of pipes 

Once established, many processes can use it for communication 

 